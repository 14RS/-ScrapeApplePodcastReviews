{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54a1760b",
   "metadata": {},
   "source": [
    "# Real-time Apple Podcast Review Scraping Simulator\n",
    "\n",
    "This program sets up a demo browser with the **selenium** module and scrolls down programmatically using Javascript commands. The demo browser's .html automatically expands as if a \"real\" user scrolls down a page. The .html page is then stored and its content is extracted with **BeautifulSoup**. The content is then added to a DataFrame with **pandas** and stored to a .csv file.\n",
    "\n",
    "A few things to keep in mind:\n",
    "- The .html page is growing bigger and bigger after each scroll and this slows down any actions performed on the page. So after about ~400 scrolls (equivalent to only a few 1000 reviews), the time it takes to scroll took about 10-20 s.\n",
    "- The .html page is already 10MB for roughly 5000 reviews.\n",
    "- This scraping method is not very efficient.\n",
    "\n",
    "To get started:\n",
    "1. Set the right url, podcast_name and path_out under the **Create .html page** section\n",
    "2. Run everything\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368bc18b",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0993b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d14e3e2",
   "metadata": {},
   "source": [
    "## Create .html page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9afa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the podcast page\n",
    "#url = 'https://podcasts.apple.com/us/podcast/black-girl-gone-a-true-crime-podcast/id1556267741?see-all=reviews'\n",
    "url = 'https://podcasts.apple.com/us/podcast/crime-junkie/id1322200189?see-all=reviews'\n",
    "\n",
    "podcast_name = 'crime-junkie'\n",
    "\n",
    "# Define output folder \n",
    "path_out = ''\n",
    "\n",
    "if not(os.path.isdir(path_out)):\n",
    "    raise Exception(f\"Output folder ({path_out}) does not exist, please create it first.\")\n",
    "\n",
    "# Define output .html file\n",
    "filename_html = f'{podcast_name}_reviews.txt'\n",
    "file_html = os.path.join(path_out, filename_html)\n",
    "\n",
    "# Define output .csv file\n",
    "filename_csv = f'{podcast_name}_reviews_table.csv'\n",
    "file_csv = os.path.join(path_out, filename_csv)\n",
    "\n",
    "# Set up Selenium webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfdf45a",
   "metadata": {},
   "source": [
    "## Start scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79d42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is kind of like the frame rate\n",
    "SCROLL_PAUSE_TIME = 0.5\n",
    "\n",
    "# Get page height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "# Initialize counter\n",
    "n = 0\n",
    "m = 0\n",
    "\n",
    "# Set total number of scrolls \n",
    "nlim = int(2*24*3600//SCROLL_PAUSE_TIME) # 2 day total scroll wait time\n",
    "mlim = int(5*60//SCROLL_PAUSE_TIME) # 10 minute time-out for scrolling\n",
    "\n",
    "# Start iterating\n",
    "while (n < nlim):\n",
    "    \n",
    "    # Try-except here, because after ~400 scrolls, the page will get laggy and the Javascript handler my time out\n",
    "    try:\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    except Exception as e:\n",
    "        # If the handler did actually time out, then we keep track of that\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        m += 1        \n",
    "        \n",
    "        # Too many time-outs will lead to a complete halt\n",
    "        if m > mlim:\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    \n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    \n",
    "    # Try-except here, because after ~400 scrolls, the page will get laggy and the Javascript handler my time out\n",
    "    try:\n",
    "        # Get page height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    except Exception as e:\n",
    "        # If the handler did actually time out, then we keep track of that\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        m += 1       \n",
    "        \n",
    "        # Too many time-outs will lead to a complete halt\n",
    "        if m > mlim:\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    # Let's check if the height has changed\n",
    "    if new_height == last_height:\n",
    "        # It didn't change, so let's track that\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        m += 1        \n",
    "        \n",
    "        # Too many time-outs will lead to a complete halt\n",
    "        if m > mlim:\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    # So it did change, let's update and move on\n",
    "    else:\n",
    "        m = 0\n",
    "    \n",
    "        # Update height\n",
    "        last_height = new_height\n",
    "\n",
    "        # Update increment\n",
    "        n += 1\n",
    "        \n",
    "    \n",
    "print(f'Done. After {n} scrolls.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2821ab53",
   "metadata": {},
   "source": [
    "## Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3291d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the HTML content of the page, \n",
    "# this you can do anytime (simply interrupt the previous step by pressing \"i\" twice on your keyboard)\n",
    "# and then run this section\n",
    "html = driver.page_source\n",
    "\n",
    "# Store to file\n",
    "with open(file_html, 'w', encoding='utf-8') as f:\n",
    "    f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531032d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the webdriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7a5e8",
   "metadata": {},
   "source": [
    "## Load html page & process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33814ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code can pick up from where it was previously left, because the stored .html page is all we need\n",
    "with open(file_html, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "# Create one big string\n",
    "html = ''.join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ca721b",
   "metadata": {},
   "source": [
    "## Get list of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Find all the reviews\n",
    "reviews = soup.find_all(\"div\", {\"class\": \"we-customer-review lockup\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa7ee13",
   "metadata": {},
   "source": [
    "## Extract info from each review and store to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bffd24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dictionary\n",
    "D = {}\n",
    "\n",
    "# Create empty lists\n",
    "ratings = []\n",
    "titles = []\n",
    "texts = []\n",
    "timestamps = []\n",
    "users = []\n",
    "\n",
    "# Build a dictionary, is a bit slow and poorly written, but I suppose its fine\n",
    "for review in reviews:\n",
    "    # '2023-02-27T13:20:53.000Z'\n",
    "    timestamp = review.time.get('datetime').strip()\n",
    "\n",
    "    # Get user\n",
    "    user = review.div.span.text.strip()\n",
    "    \n",
    "    # Get title\n",
    "    title = review.h3.text.strip()\n",
    "\n",
    "    # Get text\n",
    "    text = review.blockquote.div.p.text.strip()\n",
    "\n",
    "    # Get rating\n",
    "    rating = review.figure.get('aria-label').strip()\n",
    "    rating_int = int(rating[0])\n",
    "    \n",
    "    # Append\n",
    "    timestamps.append(timestamp)\n",
    "    ratings.append(rating_int)\n",
    "    titles.append(title)\n",
    "    texts.append(text)\n",
    "    users.append(user)\n",
    "    \n",
    "\n",
    "# Add to dictionary\n",
    "D['user'] = users\n",
    "D['timestamp'] = timestamps\n",
    "D['rating'] = ratings\n",
    "D['title'] = titles\n",
    "D['text'] = texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04eabb5",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908bb846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store to dataframe\n",
    "df = pd.DataFrame(D)\n",
    "\n",
    "# Export to .csv\n",
    "df.to_csv(file_csv, index=False, sep='\\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701a7497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
